{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Stocker\n",
    "## Using the Twitter API to implement sentiment analysis on different sets of stocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1) Getting the Tweepy API working for Python\n",
    "\n",
    "* Import the dependencies for the rest of the project here, this section will be kept up-to-date\n",
    "* Create a twitter account (out of scope) and through the developer section, get a set of `OAuth` credentials\n",
    "* Instantiate the api and make some test searches\n",
    "* Define some helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Import the necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tweepy\n",
    "from tweepy import OAuthHandler, Stream, StreamListener\n",
    "tweepy.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "import pandas_datareader.data as pdr\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config/keys.txt']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.read('config/keys.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Authenticate User: you should use ideally use your own login credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "consumer_key = config['DEFAULT']['consumer_key']\n",
    "consumer_secret = config['DEFAULT']['consumer_secret']\n",
    "access_token = config['DEFAULT']['access_token']\n",
    "access_secret = config['DEFAULT']['access_secret']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_secret)\n",
    "\n",
    "# plug into the matrix\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Test the tweepy api with Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_stock = 'Microsoft'\n",
    "test_ticker = 'MSFT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_results = api.search(q=test_stock, count=10, lang='en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-03 00:15:48\n",
      "RT @chrisheauxx: nigga recorded this with microsoft word 2003 https://t.co/eSeMrdGPjZ\n",
      "2019-04-03 00:15:47\n",
      "@DChaikovskiy @THEREALRTU You're saying this bullshtick because you only have a Sony system because Nintendo and Mi… https://t.co/xlodbfWvMp\n",
      "2019-04-03 00:15:46\n",
      "@USCSIsrael @mikejwalker @Microsoft @DigitalChamber Nothing to see here\n"
     ]
    }
   ],
   "source": [
    "for s in search_results[:3]:\n",
    "    print(s.created_at)\n",
    "    print(s.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Define helper functions:\n",
    "\n",
    "* One to get the corpus from a tweet\n",
    "* One to perform a twitter search with a string and collect 100 tweets before a given date\n",
    "* One to combine gainers and losers into a set of 300 tweets, assigning each tweet to the company"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_corpus(status):\n",
    "    \"\"\"\n",
    "    Given a tweepy.models.Status object, returns the corpus as a str object\n",
    "    \n",
    "    :params: status, tweepy.models.Status\n",
    "    :returns: corpus, str\n",
    "    \"\"\"\n",
    "    if isinstance(status, tweepy.models.Status):\n",
    "        return status.text\n",
    "    else:\n",
    "        raise TypeError(\"Input not of type tweepy.api.Status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def collect_tweets(query, \n",
    "                   limit=1000,\n",
    "                   dt=datetime.datetime.now(),\n",
    "                   tz='US/Eastern'):\n",
    "    \n",
    "    assert(isinstance(query, str))\n",
    "\n",
    "    local_tz = pytz.timezone(tz)\n",
    "    local_dt = local_tz.localize(dt)\n",
    "    \n",
    "        \n",
    "    valid_results = []\n",
    "    for s in tweepy.Cursor(api.search, q=query, rpp=10,count=100, lang='en').items(limit):\n",
    "        if local_tz.localize(s.created_at) < local_dt:\n",
    "            \n",
    "            valid_results.append(s)\n",
    "            \n",
    "    if len(valid_results) < 100:\n",
    "        print(\"WARN: Less than 100 results, consider expanding search\")\n",
    "        \n",
    "    return valid_results[:100]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def assemble_corpus(tweet_dict):\n",
    "    pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = collect_tweets('GRANITE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @RepAnnieKuster: NH families deserve to know their water is protected from pollution, yet the president’s #DirtyWaterRule will undo crit…'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets[0].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Determining the Winners and Losers for a given day\n",
    "\n",
    "* Define the scope of the problem. Here, I have chosen the NASDAQ index and have pulled a .csv file of the companies\n",
    "* Define functions to find the winners and losers, winners and losers are defined by their diff = price_close - price_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1) Read in all companies on the NASDAQ, I have pre-populated a list of the companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ticker_df = pd.read_csv('files\\companylist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ticker_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tickers = ticker_df['Symbol']\n",
    "tickers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# useful datetime variable\n",
    "start_dt = datetime.datetime(2019, 3, 27)\n",
    "end_dt = start_dt + datetime.timedelta(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) define three helper functions: \n",
    "\n",
    "* One to compute the stock's gain or loss for a given day\n",
    "* One to compile a dictionary of all (or some) of the NASDAQs stocks' gains/losses for a given day.\n",
    "By default, the limit is set at 50 out of the 3500 or so NASDAQ companies. Simply set limit=None to\n",
    "scan the entire NASDAQ index\n",
    "* One to identify the winners and losers given the dictionary and return a winner's dictionary and a loser's\n",
    "dictionary based on the differential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _get_diff(df):\n",
    "    assert(df.shape[0] == 1)\n",
    "    return float(df['close'] - df['open']) / float(df['open'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_diffs(tickers, \n",
    "                  limit=50, \n",
    "                  dt=datetime.datetime.now() - datetime.timedelta(1)):\n",
    "    \n",
    "    if limit and limit < len(tickers):\n",
    "        _tickers = tickers[:limit]\n",
    "    else:\n",
    "        _tickers = tickers\n",
    "    \n",
    "    _diffs = dict()\n",
    "    \n",
    "    for ticker in _tickers:\n",
    "    \n",
    "        try:\n",
    "            _df = pdr.DataReader(ticker, 'iex', dt, dt)\n",
    "            diff_value = _get_diff(_df)\n",
    "            _diffs[ticker] = diff_value\n",
    "        except Exception as e:\n",
    "            print(ticker, _df.shape)\n",
    "            \n",
    "    return _diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_gainers_and_losers(diff_dict):\n",
    "    \n",
    "    _df = pd.DataFrame([diff_dict.keys(), diff_dict.values()]).T\n",
    "    _df.dropna(axis=0, inplace=True)\n",
    "    _df.columns = ['ticker', 'diff']\n",
    "    _df.sort_values('diff', inplace=True, ascending=False)\n",
    "    _df.set_index('ticker', inplace=True, drop=True)\n",
    "    \n",
    "    winners = _df.iloc[:3, :]\n",
    "    losers = _df.iloc[-3:, :]\n",
    "    \n",
    "    return winners.to_dict()['diff'], losers.to_dict()['diff']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "diffs = get_all_diffs(tickers, 200, start_dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gainers, losers = find_gainers_and_losers(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gainers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "losers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Combining the previous sections\n",
    "\n",
    "Now that we have achieved the basic abilities to use the tweepy API and the pandas data reader, we want to abstract\n",
    "their functionality into a more structured piece of software with clear inputs and outputs and robust paremeter handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
